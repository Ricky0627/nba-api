import pandas as pd
import sqlite3
import time
import random
import os
import datetime
import warnings
from nba_api.stats.endpoints import teamgamelogs
from requests.exceptions import ReadTimeout, ConnectTimeout, ConnectionError
from urllib3.exceptions import ProtocolError
from tqdm import tqdm

# å¿½ç•¥ NBA API çš„è­¦å‘Šè¨Šæ¯
warnings.filterwarnings("ignore", category=UserWarning, module="nba_api")

# ===========================
# âš™ï¸ é›²ç«¯è‡ªå‹•åŒ–è¨­å®šå€
# ===========================
DB_PATH = 'data/nba_current.db'  # ğŸ‘ˆ æ”¹ç‚ºè®€å¯«è¼•é‡ç´šçš„æ–°è³‡æ–™åº«
START_YEAR = 2025                # ğŸ‘ˆ é›²ç«¯åªè² è²¬ç•¶å‰è³½å­£
END_YEAR = 2026     
SEASON_TYPES = ['Regular Season', 'Playoffs'] 

TIMEOUT_SECONDS = 30             # ä½¿ç”¨ç§äºº Proxyï¼Œé€Ÿåº¦å¿«ï¼Œè¶…æ™‚å¯ä»¥ç¸®çŸ­
MAX_RETRIES = 5        
RETRY_DELAY = 3        

# ===========================
# ğŸ›¡ï¸ Proxy ä»£ç†ä¼ºæœå™¨è¨­å®š
# ===========================
def setup_proxy():
    """å¾ GitHub Secrets è®€å–å°ˆå±¬ Proxy ä¸¦è¨­å®šç‚ºå…¨åŸŸç’°å¢ƒè®Šæ•¸"""
    proxy_url = os.environ.get('PROXY_URL')
    if proxy_url:
        os.environ['HTTP_PROXY'] = proxy_url
        os.environ['HTTPS_PROXY'] = proxy_url
        print("âœ… å·²æˆåŠŸè¼‰å…¥ Webshare ç§äºº Proxy è¨­å®šï¼")
    else:
        print("âš ï¸ è­¦å‘Šï¼šæœªåµæ¸¬åˆ° PROXY_URL ç’°å¢ƒè®Šæ•¸ï¼Œå°‡ä½¿ç”¨ GitHub é è¨­ IP é€£ç·šï¼ˆæ¥µå¯èƒ½è¢«æ“‹ï¼‰ã€‚")

# === çœŸå¯¦ç€è¦½å™¨å½è£ ===
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15'
]

def get_headers():
    """æ¯æ¬¡è«‹æ±‚éš¨æ©Ÿç”¢ç”Ÿä¸€çµ„æ­£å¸¸çš„ç€è¦½å™¨æ¨™é ­ï¼Œé¿å…è¢«é˜²ç«ç‰†é˜»æ“‹"""
    return {
        'Host': 'stats.nba.com',
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'application/json, text/plain, */*',
        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
        'Referer': 'https://www.nba.com/',
        'Origin': 'https://www.nba.com',
        'x-nba-stats-origin': 'stats',
        'x-nba-stats-token': 'true',
    }

def init_db():
    if not os.path.exists('data'):
        os.makedirs('data')
    conn = sqlite3.connect(DB_PATH)
    return conn

def is_current_season(season_str):
    start_year = int(season_str.split('-')[0])
    current_year = datetime.datetime.now().year
    return start_year >= (current_year - 1)

def is_future_playoffs(season_str):
    """ğŸ”® é çŸ¥æœªä¾†æ””æˆªå™¨ï¼šåˆ¤æ–·è©²è³½å­£çš„å­£å¾Œè³½æ˜¯å¦é‚„æ²’é–‹æ‰“"""
    start_year = int(season_str.split('-')[0])
    playoff_year = start_year + 1 
    now = datetime.datetime.now()
    if now.year < playoff_year or (now.year == playoff_year and now.month < 4):
        return True
    return False

def check_season_status(conn, table_name, season, season_type):
    if is_current_season(season): return 'UPDATE'
    try:
        cursor = conn.cursor()
        cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'")
        if not cursor.fetchone(): return 'EMPTY'
        cursor.execute(f"SELECT COUNT(*) FROM {table_name} WHERE SEASON_YEAR = ? AND SEASON_TYPE = ?", (season, season_type))
        count = cursor.fetchone()[0]
        if count > 100: return 'SKIP'
        return 'EMPTY'
    except:
        return 'EMPTY'

def get_latest_date(conn, table_name, season, season_type):
    """æ‰¾å‡ºè³‡æ–™åº«ä¸­è©²è³½å­£æœ€æ–°çš„ä¸€ç­†æ—¥æœŸ"""
    try:
        cursor = conn.cursor()
        query = f"SELECT MAX(GAME_DATE) FROM {table_name} WHERE SEASON_YEAR = ? AND SEASON_TYPE = ?"
        cursor.execute(query, (season, season_type))
        res = cursor.fetchone()
        if res and res[0]:
            y, m, d = res[0][:10].split('-')
            return f"{m}/{d}/{y}"
    except:
        pass
    return ""

def save_to_db_incremental(conn, df, table_name):
    if df.empty: return
    try:
        cursor = conn.cursor()
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns_info = cursor.fetchall()
        
        if columns_info: 
            existing_cols = [info[1] for info in columns_info]
            for col in df.columns:
                if col not in existing_cols:
                    try: cursor.execute(f"ALTER TABLE {table_name} ADD COLUMN {col} TEXT")
                    except: pass 
            conn.commit()

        df.head(0).to_sql(table_name, conn, if_exists='append', index=False)
        try:
            existing = pd.read_sql(f"SELECT GAME_ID, TEAM_ID FROM {table_name}", conn)
            existing_keys = set(existing['GAME_ID'].astype(str) + '_' + existing['TEAM_ID'].astype(str))
        except:
            existing_keys = set()
        
        df_keys = df['GAME_ID'].astype(str) + '_' + df['TEAM_ID'].astype(str)
        new_data = df[~df_keys.isin(existing_keys)].copy()
        
        if not new_data.empty:
            new_data.to_sql(table_name, conn, if_exists='append', index=False)
        else:
            pass 

    except Exception as e:
        tqdm.write(f"   âŒ å¯«å…¥è³‡æ–™åº«éŒ¯èª¤: {e}")

def fetch_with_retry(season, season_type, measure_type, date_from=None, date_to=None):
    """å¸¶æœ‰æ™ºæ…§é€€é¿èˆ‡å½è£çš„æŠ“å–å‡½æ•¸"""
    for attempt in range(MAX_RETRIES):
        try:
            logs = teamgamelogs.TeamGameLogs(
                season_nullable=season,
                season_type_nullable=season_type,
                measure_type_player_game_logs_nullable=measure_type,
                date_from_nullable=date_from,
                date_to_nullable=date_to,
                headers=get_headers(),
                timeout=TIMEOUT_SECONDS
            )
            return logs.get_data_frames()[0]
            
        except (ReadTimeout, ConnectTimeout, ConnectionError, ProtocolError) as e:
            wait_time = RETRY_DELAY + (attempt * 3) + random.uniform(1.5, 3.5)
            error_brief = str(e).split("',")[-1].strip(" )\"'")[:30] 
            tqdm.write(f"   âš ï¸ ä¼ºæœå™¨ç„¡å›æ‡‰ ({measure_type})ï¼Œç­‰ {wait_time:.1f} ç§’é‡è©¦... [{error_brief}]")
            time.sleep(wait_time)
            
        except Exception as e:
            if "no data" in str(e).lower() or "timeout" in str(e).lower():
                break
            tqdm.write(f"   âš ï¸ API ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ ({measure_type}): {e}")
            break
            
    return pd.DataFrame()

def fetch_season_stats(conn):
    seasons = [f"{y}-{str(y+1)[-2:]}" for y in range(START_YEAR, END_YEAR)]
    
    tasks = [
        {'type': 'Base', 'table': 'boxscore_base'}, 
        {'type': 'Advanced', 'table': 'boxscore_advanced'}
    ]
    
    pbar = tqdm(total=len(seasons) * len(SEASON_TYPES) * len(tasks), desc="åŒæ­¥è³½å­£æ•¸æ“š")

    for season in seasons:
        for s_type in SEASON_TYPES:
            
            if s_type == 'Playoffs' and is_future_playoffs(season):
                tqdm.write(f"   â­ï¸ [è·³é] {season} å­£å¾Œè³½å°šæœªé–‹æ‰“ï¼Œå¿½ç•¥ç„¡æ•ˆè«‹æ±‚ã€‚")
                pbar.update(len(tasks)) 
                continue

            for task in tasks:
                m_type = task['type']
                table_name = task['table']
                
                status = check_season_status(conn, table_name, season, s_type)
                
                if status == 'SKIP':
                    pbar.update(1)
                    continue
                
                # ==========================================
                # ğŸ”¥ é€æ—¥åˆ‡å‰²æ³• (æ›´æ–°é›²ç«¯æœ€æ–°é€²åº¦)
                # ==========================================
                if status == 'UPDATE' and is_current_season(season):
                    last_date_str = get_latest_date(conn, table_name, season, s_type)
                    
                    if not last_date_str:
                        last_date_str = f"10/15/{season.split('-')[0]}"
                    
                    start_dt = datetime.datetime.strptime(last_date_str, "%m/%d/%Y")
                    start_dt -= datetime.timedelta(days=1) 
                    end_dt = datetime.datetime.now()

                    date_list = []
                    curr = start_dt
                    while curr <= end_dt:
                        date_list.append(curr.strftime("%m/%d/%Y"))
                        curr += datetime.timedelta(days=1)

                    if m_type == 'Base': 
                        tqdm.write(f"   ğŸ“… [{season} {s_type}] å•Ÿå‹•é€æ—¥æŠ“å–æ¨¡å¼ï¼Œæº–å‚™è£œé½Š {len(date_list)} å¤©...")

                    success_days = 0
                    for d in date_list:
                        df = fetch_with_retry(season, s_type, m_type, date_from=d, date_to=d)
                        if not df.empty:
                            df['SEASON_YEAR'] = season
                            df['SEASON_TYPE'] = s_type
                            save_to_db_incremental(conn, df, table_name)
                            success_days += 1
                        
                        time.sleep(random.uniform(0.5, 1.2))
                    
                    tqdm.write(f"   âœ… [{table_name}] æˆåŠŸå®Œæˆæ›´æ–°ã€‚")

                else:
                    tqdm.write(f"   â³ [{table_name}] è«‹æ±‚ {season} å®Œæ•´è³‡æ–™...")
                    df = fetch_with_retry(season, s_type, m_type)
                    if not df.empty:
                        df['SEASON_YEAR'] = season
                        df['SEASON_TYPE'] = s_type
                        save_to_db_incremental(conn, df, table_name)
                    time.sleep(random.uniform(1.0, 2.0))
                
                pbar.update(1)

    pbar.close()
    print("é›²ç«¯æ•¸æ“šåŒæ­¥å®Œæˆï¼")

if __name__ == "__main__":
    print(f"ğŸš€ å•Ÿå‹• NBA æ•¸æ“šçˆ¬èŸ² (é›²ç«¯å…¨è‡ªå‹•æ›´æ–°ç‰ˆ)")
    # åˆå§‹åŒ– Proxy
    setup_proxy()
    
    conn = init_db()
    try:
        fetch_season_stats(conn)
    finally:
        conn.close()