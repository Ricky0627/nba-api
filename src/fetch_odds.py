import requests
from bs4 import BeautifulSoup
import sqlite3
import time
import random
import datetime
from datetime import timedelta
import re
import os

# ===========================
# âš™ï¸ é›²ç«¯è‡ªå‹•åŒ–è¨­å®šå€
# ===========================
DB_PATH = 'data/nba_current.db'    # ğŸ‘ˆ æ”¹ç‚ºè®€å¯«è¼•é‡ç´šçš„æ–°è³‡æ–™åº«
DEFAULT_START_DATE = "2025-10-15"  # ğŸ‘ˆ é›²ç«¯ç‰ˆåªè² è²¬ 2025-26 ç•¶å‰è³½å­£
DEFAULT_END_DATE   = "2026-06-30"

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

# ===========================
# ğŸ›¡ï¸ Proxy ä»£ç†ä¼ºæœå™¨è¨­å®š
# ===========================
def setup_proxy():
    """å¾ GitHub Secrets è®€å–å°ˆå±¬ Proxy ä¸¦è¨­å®šç‚ºå…¨åŸŸç’°å¢ƒè®Šæ•¸"""
    proxy_url = os.environ.get('PROXY_URL')
    if proxy_url:
        os.environ['HTTP_PROXY'] = proxy_url
        os.environ['HTTPS_PROXY'] = proxy_url
        print("âœ… å·²æˆåŠŸè¼‰å…¥ Webshare ç§äºº Proxy è¨­å®šï¼")
    else:
        print("âš ï¸ è­¦å‘Šï¼šæœªåµæ¸¬åˆ° PROXY_URL ç’°å¢ƒè®Šæ•¸ï¼Œå°‡ä½¿ç”¨ GitHub é è¨­ IP é€£ç·šï¼ˆæ¥µå¯èƒ½è¢«æ“‹ï¼‰ã€‚")

# ğŸ€ éšŠåå°ç…§è¡¨ (æ•´åˆç‰ˆ)
TEAM_MAPPING = {
    "æ¹–äºº": "LAL", "æ´›æ‰ç£¯æ¹–äºº": "LAL", "å‹‡å£«": "GSW", "é‡‘å·å‹‡å£«": "GSW", "é‡‘å¡Š": "DEN", "ä¸¹ä½›é‡‘å¡Š": "DEN",
    "å¡çˆ¾æå…‹": "BOS", "æ³¢å£«é “å¡çˆ¾æå…‹": "BOS", "å¡çˆ¾æ": "BOS", "å…¬é¹¿": "MIL", "å¯†çˆ¾ç“¦åŸºå…¬é¹¿": "MIL",
    "ä¸ƒå…­äºº": "PHI", "è²»åŸä¸ƒå…­äºº": "PHI", "76äºº": "PHI", "å¤ªé™½": "PHX", "é³³å‡°åŸå¤ªé™½": "PHX", "é³³å‡°åŸ": "PHX",
    "å¿«è‰‡": "LAC", "æ´›æ‰ç£¯å¿«è‰‡": "LAC", "ç†±ç«": "MIA", "é‚é˜¿å¯†ç†±ç«": "MIA", "å°¼å…‹": "NYK", "ç´ç´„å°¼å…‹": "NYK",
    "é¨å£«": "CLE", "å…‹é‡Œå¤«è˜­é¨å£«": "CLE", "ç¨è¡Œä¿ ": "DAL", "é”æ‹‰æ–¯ç¨è¡Œä¿ ": "DAL", "å°ç‰›": "DAL", "é”æ‹‰æ–¯å°ç‰›": "DAL",
    "ç°ç†Š": "MEM", "æ›¼è²æ–¯ç°ç†Š": "MEM", "åœ‹ç‹": "SAC", "æ²™åŠ ç·¬åº¦åœ‹ç‹": "SAC", "è€é·¹": "ATL", "äºç‰¹è˜­å¤§è€é·¹": "ATL",
    "æºœé¦¬": "IND", "å°ç¬¬å®‰é‚£æºœé¦¬": "IND", "æš´é¾": "TOR", "å¤šå€«å¤šæš´é¾": "TOR", "å…¬ç‰›": "CHI", "èŠåŠ å“¥å…¬ç‰›": "CHI",
    "é›·éœ†": "OKC", "å¥§å…‹æ‹‰è·é¦¬é›·éœ†": "OKC", "ç°ç‹¼": "MIN", "æ˜å°¼è˜‡é”ç°ç‹¼": "MIN", "çˆµå£«": "UTA", "çŒ¶ä»–çˆµå£«": "UTA",
    "æ‹“è’è€…": "POR", "æ³¢ç‰¹è˜­æ‹“è’è€…": "POR", "æ‹“è’": "POR", "é­”è¡“": "ORL", "å¥§è˜­å¤šé­”è¡“": "ORL",
    "å·«å¸«": "WAS", "è¯ç››é “å·«å¸«": "WAS", "ç«ç®­": "HOU", "ä¼‘å£«é “ç«ç®­": "HOU", "é¦¬åˆº": "SAS", "è–å®‰æ±å°¼å¥§é¦¬åˆº": "SAS",
    "æ´»å¡": "DET", "åº•ç‰¹å¾‹æ´»å¡": "DET", "ç±ƒç¶²": "BKN", "å¸ƒé­¯å…‹æ—ç±ƒç¶²": "BKN", "ç´æ¾¤è¥¿ç±ƒç¶²": "BKN", "ç´æ¾¤è¥¿": "BKN", 
    "éµœé¶˜": "NOP", "ç´å¥§è‰¯éµœé¶˜": "NOP", "ç´å¥§è‰¯é»ƒèœ‚": "NOP", "ç´å¥§è‰¯": "NOP", 
    "é»ƒèœ‚": "CHA", "å¤æ´›ç‰¹é»ƒèœ‚": "CHA", "å±±è²“": "CHA", "å¤æ´›ç‰¹å±±è²“": "CHA", 
}

# éšŠååˆ¥åï¼Œç”¨æ–¼å®¹éŒ¯åŒ¹é…
CODE_ALIASES = {
    "BKN": ["BRK", "NJN"], "BRK": ["BKN"], "NJN": ["BKN"],
    "NOP": ["NOH", "NOK"], "NOH": ["NOP"], "CHA": ["CHO", "CHH"], "CHO": ["CHA"],
    "PHX": ["PHO"], "PHO": ["PHX"], "WAS": ["WSB"]
}

def get_db_connection():
    return sqlite3.connect(DB_PATH, timeout=30.0)

def date_range(start, end):
    """ç”¢ç”Ÿæ—¥æœŸåºåˆ—ï¼Œä¸¦è™•ç† T00:00:00 å•é¡Œ"""
    if 'T' in start: start = start.split('T')[0]
    if 'T' in end: end = end.split('T')[0]
    
    s = datetime.datetime.strptime(start, "%Y-%m-%d")
    e = datetime.datetime.strptime(end, "%Y-%m-%d")
    for i in range((e - s).days + 1):
        yield s + timedelta(days=i)

def find_game_in_db(date_str, h_code, a_code):
    """
    åœ¨è³‡æ–™åº«ä¸­å°‹æ‰¾å°æ‡‰çš„ game_id
    date_str: YYYYMMDD (å°ç£æ™‚é–“)
    è€ƒæ…®æ™‚å·®ï¼Œå˜—è©¦ å°ç£æ—¥æœŸ -1, 0, -2 å¤© (NBA æ¯”è³½é€šå¸¸æ˜¯å°ç£æ™‚é–“çš„æ˜¨å¤©æˆ–ç•¶å¤©)
    """
    conn = get_db_connection(); c = conn.cursor()
    dt = datetime.datetime.strptime(date_str, "%Y%m%d")
    
    # æ“´å±•ä¸»å®¢éšŠä»£ç¢¼ (è™•ç†çƒéšŠæ”¹åæˆ–ç¸®å¯«ä¸åŒ)
    h_list = [h_code] + CODE_ALIASES.get(h_code, [])
    a_list = [a_code] + CODE_ALIASES.get(a_code, [])
    
    # æœå°‹è¦–çª—ï¼šT-1 (æœ€å¸¸è¦‹), T (åŒå¤©), T-2 (æ¥µå°‘è¦‹)
    for diff in [1, 0, 2]: 
        t_date = (dt - timedelta(days=diff)).strftime("%Y-%m-%d")
        
        # æ¨¡ç³Šæœå°‹æ—¥æœŸ (å¿½ç•¥æ™‚é–“éƒ¨åˆ†)
        date_pattern = f"{t_date}%"
        
        for h in h_list:
            for a in a_list:
                c.execute('SELECT game_id FROM games WHERE home_team=? AND away_team=? AND date LIKE ?', (h, a, date_pattern))
                res = c.fetchone()
                if res: 
                    conn.close()
                    return res[0]
                    
    conn.close()
    return None

def parse_cell_robust(text):
    """
    ğŸ”¥ æ ¸å¿ƒå¼•æ“ V5 (ä¿®å¾©ç‰ˆ)ï¼š
    è§£æ±ºå®Œè³½å¾Œã€Œè³ ç‡é»è‘—è¼¸è´å­—çœ¼ã€(å¦‚ "1.75è´50%") å°è‡´æŠ“ä¸åˆ°è³‡æ–™çš„å•é¡Œã€‚
    """
    if not text or text == '-' or 'æœªé–‹' in text: return None, None
    
    # 1. é è™•ç†ï¼šæª¢æŸ¥ PK
    is_pk = 'PK' in text.upper()
        
    # 2. æ¸…æ´—è³‡æ–™ï¼šç§»é™¤æ‹¬è™Ÿå…§çš„è©³æƒ…ï¼Œä»¥åŠã€Œè´/è¼¸ã€å¾Œé¢çš„ç™¾åˆ†æ¯”
    text = re.sub(r'\(.*?\)', '', text).replace('&nbsp;', '').strip()
    
    # 3. ä½¿ç”¨ Regex å¼·åˆ¶æå–æ‰€æœ‰æ•¸å­— (æ”¯æ´è² è™Ÿèˆ‡å°æ•¸é»)
    nums = re.findall(r'[-+]?\d+\.\d+|[-+]?\d+', text)
    
    final_val = None
    final_odds = None
    
    if not nums:
        if is_pk: return 0.0, None
        return None, None

    # è½‰æˆ float åˆ—è¡¨
    nums_float = []
    for n in nums:
        try: nums_float.append(float(n))
        except: pass

    if not nums_float: return None, None

    # 4. æ™ºæ…§åˆ†é…é‚è¼¯
    if len(nums_float) == 1:
        val = nums_float[0]
        if val > 50 or val == 0: # å¤§å°åˆ†åˆ†æ•¸æˆ–PK
            final_val = val
        else:
            final_odds = val # è³ ç‡
            
    elif len(nums_float) >= 2:
        final_odds = nums_float[-1] # æœ€å¾Œä¸€å€‹æ˜¯è³ ç‡
        final_val = nums_float[-2]  # å€’æ•¸ç¬¬äºŒå€‹æ˜¯åˆ†æ•¸

    if is_pk: final_val = 0.0

    return final_val, final_odds

def parse_tot_smart(txt):
    """è§£æå¤§å°åˆ†"""
    if not txt: return None, None, False
    is_ov = 'å¤§' in txt
    v, o = parse_cell_robust(txt)
    if v is not None: v = abs(v) # å¤§å°åˆ†ä¸€å®šæ˜¯æ­£æ•¸
    return v, o, is_ov

def update_db(game_id, data):
    """æ›´æ–°è³‡æ–™åº«"""
    conn = get_db_connection()
    c = conn.cursor()
    cols = []
    vals = []
    for k, v in data.items():
        cols.append(f"{k}=?")
        vals.append(v)
    vals.append(game_id)
    if cols:
        sql = f"UPDATE games SET {', '.join(cols)} WHERE game_id=?"
        try: c.execute(sql, vals); conn.commit()
        except: pass
    conn.close()

def get_db_date_range():
    """æ‰¾å‡ºè³‡æ–™åº«ä¸­æœ€æ™šçš„è³ ç‡æ—¥æœŸï¼Œä½œç‚ºä¸‹æ¬¡çˆ¬èŸ²çš„èµ·é»"""
    if not os.path.exists(DB_PATH):
        return DEFAULT_START_DATE, DEFAULT_END_DATE

    conn = get_db_connection()
    c = conn.cursor()
    
    try:
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰è³ ç‡æ•¸æ“š
        c.execute("SELECT MAX(date) FROM games WHERE tw_spread_score IS NOT NULL")
        last_odds_date = c.fetchone()[0]
        
        # ä»Šå¤©çš„æ—¥æœŸ
        today = datetime.datetime.now().strftime("%Y-%m-%d")

        if last_odds_date:
            print(f"   â„¹ï¸ è³‡æ–™åº«å·²æœ‰è³ ç‡è‡³ {last_odds_date}ï¼Œå°‡å¾éš”å¤©é–‹å§‹çˆ¬å–ã€‚")
            if 'T' in last_odds_date: last_odds_date = last_odds_date.split('T')[0]
            
            last_dt = datetime.datetime.strptime(last_odds_date, "%Y-%m-%d")
            next_day = (last_dt + timedelta(days=1)).strftime("%Y-%m-%d")
            return next_day, DEFAULT_END_DATE
        else:
            # å¦‚æœæ²’è³ ç‡ï¼Œæ‰¾æœ€æ—©çš„æ¯”è³½æ—¥æœŸ
            c.execute("SELECT MIN(date) FROM games")
            first_game_date = c.fetchone()[0]
            if first_game_date:
                if 'T' in first_game_date: first_game_date = first_game_date.split('T')[0]
                print(f"   â„¹ï¸ å°šæœªæœ‰ä»»ä½•è³ ç‡è³‡æ–™ã€‚å°‡å¾è³‡æ–™åº«æœ€æ—©æ—¥æœŸ {first_game_date} é–‹å§‹çˆ¬å–ã€‚")
                return first_game_date, DEFAULT_END_DATE
            else:
                return DEFAULT_START_DATE, DEFAULT_END_DATE
            
    except Exception as e:
        print(f"   âš ï¸ è®€å–æ—¥æœŸç¯„åœéŒ¯èª¤: {e}")
        return DEFAULT_START_DATE, DEFAULT_END_DATE
    finally:
        conn.close()

def crawl_odds_incremental():
    print("ğŸ” æ­£åœ¨æª¢æŸ¥è³‡æ–™åº«é€²åº¦...")
    start_date, end_date = get_db_date_range()
    
    # é˜²æ­¢çˆ¬å–æœªä¾† (PlaySport æœ€å¤šåªæœƒæœ‰æœªä¾†å¹¾å¤©çš„ç›¤)
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    limit_date = (datetime.datetime.now() + timedelta(days=7)).strftime("%Y-%m-%d") # æœ€å¤šçˆ¬åˆ°æœªä¾†ä¸€é€±
    
    if start_date > limit_date:
        print("âœ… è³ ç‡è³‡æ–™å·²æ˜¯æœ€æ–°ï¼Œç„¡éœ€æ›´æ–°ã€‚")
        return

    print(f"ğŸš€ PlaySport é‹å½©ç›¤çˆ¬èŸ² (é›²ç«¯è‡ªå‹•åŒ–ç‰ˆ) å•Ÿå‹•...")
    print(f"ğŸ“… ç¯„åœ: {start_date} ~ {min(end_date, limit_date)}")
    
    for curr in date_range(start_date, min(end_date, limit_date)):
        date_str = curr.strftime("%Y%m%d") # ç¶²å€ç”¨ YYYYMMDD
        display = curr.strftime("%Y-%m-%d")
        
        # ğŸ”¥ ä½¿ç”¨æ›´ç©©å®šçš„æ­·å²è³½æœç¶²å€
        url = f"https://www.playsport.cc/gamesData/result?allianceid=3&gametime={date_str}"
        print(f"   ğŸ“¥ æ­£åœ¨çˆ¬å– {display} ... ", end="")
        
        try:
            # ç”±æ–¼å·²è¨­å®š os.environ['HTTPS_PROXY']ï¼Œé€™è£¡çš„ requests æœƒè‡ªå‹•èµ° Webshare ä»£ç†
            resp = requests.get(url, headers=HEADERS, timeout=15)
            if resp.status_code != 200: 
                print(f"å¤±æ•— ({resp.status_code})")
                continue
            
            soup = BeautifulSoup(resp.content, 'html.parser')
            rows = soup.find_all('tr', attrs={'gameid': True})
            
            count = 0
            i = 0
            while i < len(rows) - 1:
                r_away = rows[i]
                r_home = rows[i+1]
                
                if r_away.get('gameid') != r_home.get('gameid'):
                    i += 1; continue
                    
                td_info = r_away.find('td', class_='td-teaminfo')
                if not td_info: i += 2; continue
                
                teams = [l.text.strip() for l in td_info.find_all('a') if 'teamid=' in l.get('href', '')]
                if len(teams) < 2: i += 2; continue
                
                c_away, c_home = teams[0], teams[1]
                code_away = TEAM_MAPPING.get(c_away)
                code_home = TEAM_MAPPING.get(c_home)
                
                if not code_away or not code_home: i += 2; continue
                
                gid = find_game_in_db(date_str, code_home, code_away)
                if not gid: 
                    i += 2; continue
                
                data = {}
                
                # 1. é‹å½©è®“åˆ† (Spread)
                try:
                    t_spr_a = r_away.find('td', 'td-bank-bet01').get_text(separator=',').strip()
                    t_spr_h = r_home.find('td', 'td-bank-bet01').get_text(separator=',').strip()
                    _, o_spr_a = parse_cell_robust(t_spr_a)
                    s_spr, o_spr_h = parse_cell_robust(t_spr_h)
                    
                    if s_spr is not None: data['tw_spread_score'] = s_spr
                    if o_spr_h: data['tw_spread_home_odds'] = o_spr_h
                    if o_spr_a: data['tw_spread_away_odds'] = o_spr_a
                except: pass
                
                # 2. é‹å½©å¤§å° (Total)
                try:
                    t_tot_a = r_away.find('td', 'td-bank-bet02').get_text(separator=',').strip()
                    t_tot_h = r_home.find('td', 'td-bank-bet02').get_text(separator=',').strip()
                    v1, o1, is_ov1 = parse_tot_smart(t_tot_a)
                    v2, o2, is_ov2 = parse_tot_smart(t_tot_h)
                    
                    final_tot = v1 if v1 and v1 > 100 else (v2 if v2 and v2 > 100 else None)
                    if final_tot: data['tw_total_score'] = final_tot
                    
                    if o1: data['tw_total_over_odds' if is_ov1 else 'tw_total_under_odds'] = o1
                    if o2: data['tw_total_over_odds' if is_ov2 else 'tw_total_under_odds'] = o2
                except: pass

                # 3. é‹å½©ç¨è´ (Moneyline)
                try:
                    t_ml_a = r_away.find('td', 'td-bank-bet03').get_text(separator=',').strip()
                    t_ml_h = r_home.find('td', 'td-bank-bet03').get_text(separator=',').strip()
                    _, o_ml_a = parse_cell_robust(t_ml_a)
                    _, o_ml_h = parse_cell_robust(t_ml_h)
                    if o_ml_a: data['tw_moneyline_away'] = o_ml_a
                    if o_ml_h: data['tw_moneyline_home'] = o_ml_h
                except: pass
                
                if data:
                    update_db(gid, data)
                    count += 1
                i += 2
            
            print(f"æ›´æ–° {count} å ´")
            # ç¦®è²Œæ€§å»¶é²
            time.sleep(random.uniform(1.0, 2.0))
            
        except Exception as e:
            print(f"éŒ¯èª¤: {e}")
            pass

if __name__ == "__main__":
    print(f"ğŸš€ å•Ÿå‹• NBA é‹å½©è³ ç‡çˆ¬èŸ² (é›²ç«¯å…¨è‡ªå‹•æ›´æ–°ç‰ˆ)")
    # åˆå§‹åŒ– Proxy
    setup_proxy()
    
    if not os.path.exists(DB_PATH):
        print(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™åº« {DB_PATH}ï¼Œè«‹å…ˆåŸ·è¡Œ init_games_table.py")
    else:
        crawl_odds_incremental()